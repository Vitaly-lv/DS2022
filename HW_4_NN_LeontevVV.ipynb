{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vitaly-lv/DS2022/blob/main/HW_4_NN_LeontevVV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнить LSTM, RNN и GRU на задаче предсказания части речи (качество предсказания, скорость обучения, время инференса модели)"
      ],
      "metadata": {
        "id": "_fhC-2z4YRNP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e2c650-dfd3-47e9-9566-ab6d57871454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/My Drive/'\n",
        "train_lang = 'en'"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetSeq(Dataset):\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\t#open file\n",
        "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
        "            train = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        train = [x for x in train if not '_ ' in x]\n",
        "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
        "        self.target_vocab = {'<pad>': 0} # {p: 1, a: 2, r: 3, pu: 4}\n",
        "        self.word_vocab = {'<pad>': 0} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
        "        self.char_vocab = {'<pad>': 0} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
        "\t    \n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "        for line in train:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], # [1, 2, 3, 4, 6] len=5\n",
        "        }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq(data_dir)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "vocab_size = len(dataset.word_vocab) + 1\n",
        "n_classes = len(dataset.target_vocab) + 1\n",
        "n_chars = len(dataset.char_vocab) + 1\n",
        "emb_dim = 256\n",
        "hidden = 256\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "Rww4C8i5JO-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "SsHqwGdkzOLl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqdKnijNW7ob"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "KTW6Ykn3ywgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Обучение LSTM\n",
        "%%time\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    \n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        predict = model(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSyGiiCDy8rA",
        "outputId": "801ca9fa-7ca7-429e-ecb5-b692961d4b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.877631664276123\n",
            "epoch: 0, step: 100, loss: 0.2676323652267456\n",
            "epoch: 0, step: 200, loss: 0.13285693526268005\n",
            "epoch: 1, step: 0, loss: 0.18667706847190857\n",
            "epoch: 1, step: 100, loss: 0.24471642076969147\n",
            "epoch: 1, step: 200, loss: 0.17065216600894928\n",
            "epoch: 2, step: 0, loss: 0.16327928006649017\n",
            "epoch: 2, step: 100, loss: 0.13714388012886047\n",
            "epoch: 2, step: 200, loss: 0.06251411885023117\n",
            "epoch: 3, step: 0, loss: 0.07345478236675262\n",
            "epoch: 3, step: 100, loss: 0.05372733622789383\n",
            "epoch: 3, step: 200, loss: 0.09181215614080429\n",
            "epoch: 4, step: 0, loss: 0.057906899601221085\n",
            "epoch: 4, step: 100, loss: 0.08990530669689178\n",
            "epoch: 4, step: 200, loss: 0.07005158811807632\n",
            "epoch: 5, step: 0, loss: 0.04683231934905052\n",
            "epoch: 5, step: 100, loss: 0.053118180483579636\n",
            "epoch: 5, step: 200, loss: 0.04486418142914772\n",
            "epoch: 6, step: 0, loss: 0.051417771726846695\n",
            "epoch: 6, step: 100, loss: 0.06038067117333412\n",
            "epoch: 6, step: 200, loss: 0.030528919771313667\n",
            "epoch: 7, step: 0, loss: 0.0378965325653553\n",
            "epoch: 7, step: 100, loss: 0.0395948700606823\n",
            "epoch: 7, step: 200, loss: 0.03534238040447235\n",
            "epoch: 8, step: 0, loss: 0.04095989465713501\n",
            "epoch: 8, step: 100, loss: 0.027180930599570274\n",
            "epoch: 8, step: 200, loss: 0.044038593769073486\n",
            "epoch: 9, step: 0, loss: 0.03350610285997391\n",
            "epoch: 9, step: 100, loss: 0.013856002129614353\n",
            "epoch: 9, step: 200, loss: 0.022687988355755806\n",
            "0.031171580776572227\n",
            "CPU times: user 27.7 s, sys: 530 ms, total: 28.2 s\n",
            "Wall time: 28.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инференс LSTM\n",
        "%%time\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predict = model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482b8370-48ea-4a73-d001-d1f10622df41",
        "id": "o96wOpCfzj46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.004445\n",
            "CPU times: user 3.18 ms, sys: 0 ns, total: 3.18 ms\n",
            "Wall time: 4.76 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "L8MEqi-g36Kj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr7s6WqJW7od"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "EGTRm3CF39IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCximRObW7oe",
        "outputId": "f38c5200-3844-4ba1-9d2f-9f6599410127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 3.3509182929992676\n",
            "epoch: 0, step: 100, loss: 0.18653209507465363\n",
            "epoch: 0, step: 200, loss: 0.20894348621368408\n",
            "epoch: 1, step: 0, loss: 0.16363611817359924\n",
            "epoch: 1, step: 100, loss: 0.13605424761772156\n",
            "epoch: 1, step: 200, loss: 0.1820068061351776\n",
            "epoch: 2, step: 0, loss: 0.08775459975004196\n",
            "epoch: 2, step: 100, loss: 0.1355336606502533\n",
            "epoch: 2, step: 200, loss: 0.09294583648443222\n",
            "epoch: 3, step: 0, loss: 0.08932837843894958\n",
            "epoch: 3, step: 100, loss: 0.11126276105642319\n",
            "epoch: 3, step: 200, loss: 0.11403033137321472\n",
            "epoch: 4, step: 0, loss: 0.06888501346111298\n",
            "epoch: 4, step: 100, loss: 0.09709928929805756\n",
            "epoch: 4, step: 200, loss: 0.07743091881275177\n",
            "epoch: 5, step: 0, loss: 0.04977721348404884\n",
            "epoch: 5, step: 100, loss: 0.0803999975323677\n",
            "epoch: 5, step: 200, loss: 0.07250642031431198\n",
            "epoch: 6, step: 0, loss: 0.02254757471382618\n",
            "epoch: 6, step: 100, loss: 0.06630387157201767\n",
            "epoch: 6, step: 200, loss: 0.040526919066905975\n",
            "epoch: 7, step: 0, loss: 0.03466202691197395\n",
            "epoch: 7, step: 100, loss: 0.03723450005054474\n",
            "epoch: 7, step: 200, loss: 0.04484053701162338\n",
            "epoch: 8, step: 0, loss: 0.03323253616690636\n",
            "epoch: 8, step: 100, loss: 0.04905478656291962\n",
            "epoch: 8, step: 200, loss: 0.057207535952329636\n",
            "epoch: 9, step: 0, loss: 0.023939751088619232\n",
            "epoch: 9, step: 100, loss: 0.037902768701314926\n",
            "epoch: 9, step: 200, loss: 0.03511681407690048\n",
            "0.033771008253097534\n",
            "CPU times: user 15.5 s, sys: 489 ms, total: 16 s\n",
            "Wall time: 16.2 s\n"
          ]
        }
      ],
      "source": [
        "#  Обучение RNN\n",
        "%%time\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    \n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        predict = model(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инференс RNN\n",
        "%%time\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predict = model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3178ba4-f420-4ca2-ab50-ee3f08d95949",
        "id": "ggiG8ap_4ZMV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.003450\n",
            "CPU times: user 2.59 ms, sys: 0 ns, total: 2.59 ms\n",
            "Wall time: 3.67 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRU(vocab_size, emb_dim, hidden, n_classes).to(device) # изменить название класса на GRU\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#  Обучение GRU\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2f3MATJ8GKb",
        "outputId": "6a211784-61c3-423f-c2ac-5c2376081cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 3.2314696311950684\n",
            "epoch: 0, step: 100, loss: 0.15046754479408264\n",
            "epoch: 0, step: 200, loss: 0.13895779848098755\n",
            "epoch: 1, step: 0, loss: 0.215590700507164\n",
            "epoch: 1, step: 100, loss: 0.15566414594650269\n",
            "epoch: 1, step: 200, loss: 0.15369762480258942\n",
            "epoch: 2, step: 0, loss: 0.10072372108697891\n",
            "epoch: 2, step: 100, loss: 0.13435181975364685\n",
            "epoch: 2, step: 200, loss: 0.11630139499902725\n",
            "epoch: 3, step: 0, loss: 0.06856875121593475\n",
            "epoch: 3, step: 100, loss: 0.09352385252714157\n",
            "epoch: 3, step: 200, loss: 0.1022975817322731\n",
            "epoch: 4, step: 0, loss: 0.07787217199802399\n",
            "epoch: 4, step: 100, loss: 0.04826611652970314\n",
            "epoch: 4, step: 200, loss: 0.07133965194225311\n",
            "epoch: 5, step: 0, loss: 0.0549222007393837\n",
            "epoch: 5, step: 100, loss: 0.06577060371637344\n",
            "epoch: 5, step: 200, loss: 0.05282406881451607\n",
            "epoch: 6, step: 0, loss: 0.061561696231365204\n",
            "epoch: 6, step: 100, loss: 0.04331716522574425\n",
            "epoch: 6, step: 200, loss: 0.05756833031773567\n",
            "epoch: 7, step: 0, loss: 0.041195981204509735\n",
            "epoch: 7, step: 100, loss: 0.04903562366962433\n",
            "epoch: 7, step: 200, loss: 0.05461416766047478\n",
            "epoch: 8, step: 0, loss: 0.03620560094714165\n",
            "epoch: 8, step: 100, loss: 0.03758509084582329\n",
            "epoch: 8, step: 200, loss: 0.04201743006706238\n",
            "epoch: 9, step: 0, loss: 0.02985370345413685\n",
            "epoch: 9, step: 100, loss: 0.0341225303709507\n",
            "epoch: 9, step: 200, loss: 0.02723001502454281\n",
            "0.024774493649601936\n",
            "CPU times: user 25.6 s, sys: 502 ms, total: 26.1 s\n",
            "Wall time: 26.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инференс GRU\n",
        "%%time\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predict = model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    end = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(end)"
      ],
      "metadata": {
        "id": "9CljFAzIMMEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302c571d-21bc-4375-f6e9-2bd2a5b8903a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.001987\n",
            "CPU times: user 2.75 ms, sys: 30 µs, total: 2.78 ms\n",
            "Wall time: 2.18 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По точности на обучающей выборке показатели выше у GRU, меньше всего по времени на обучение затрачивается RNN, меньшее время инференса у GRU.  "
      ],
      "metadata": {
        "id": "-57Jq-CW8NmD"
      }
    }
  ]
}